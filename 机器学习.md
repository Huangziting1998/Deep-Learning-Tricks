# 机器学习



https://www.bilibili.com/video/BV1dJ411B7gh?p=4&spm_id_from=pageDriver



监督学习：SVM、神经网络

无监督学习：EM、clustering、PCA

半监督学习

强化学习：自动驾驶





## SVM—支持向量机



支持向量机是一种**二分类模型**，它的基本模型是**定义在特征空间上的间隔最大的线性分类器**，**间隔最大使它有别于感知机**；SVM还包括**核技巧**，这使它成为**实质上的非线性分类器**，SVM的**学习策略就是间隔最大化**，可形式化为一个求解凸二次规划的问题，也**等价于正则化的合页损失函数的最小化问题**，**SVM的的学习算法就是求解凸二次规划的最优化算法**；



**1.SVM的原理**

SVM学习的基本想法是求解**能够正确划分训练数据集并且几何间隔最大的分离超平面**
$$
\boldsymbol{w} \cdot x+b=0
$$
即为分离超平面，对于线性可分的数据集来说，这样的超平面有无穷多个（即感知机），但是几何间隔最大的分离超平面却是唯一的



**2. SVM的核函数了解哪些  为什么要用核函数**

当样本在原始空间线性不可分时，可将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分：



**①线性核函数**
$$
\kappa\left(x, x_{i}\right)=x \cdot x_{i}
$$
线性核，主要用于**线性可分**的情况，我们可以看到**特征空间到输入空间的维度是一样**的，其**参数少**速度快，对于线性可分数据，其分类效果很理想



**②多项式核函数**
$$
\kappa\left(x, x_{i}\right)=\left(\left(x \cdot x_{i}\right)+1\right)^{d}
$$
多项式核函数可以实现**将低维的输入空间映射到高纬的特征空间**，但是**多项式核函数的参数多**，当多项式的**阶数比较高**的时候，**核矩阵的元素值将趋于无穷大或者无穷小**，**计算复杂度会大**到无法计算



**③高斯（RBF）核函数**
$$
\kappa\left(x, x_{i}\right)=\exp \left(-\frac{\left\|x-x_{i}\right\|^{2}}{\delta^{2}}\right)
$$


高斯径向基函数是一**种局部性强的核函数**，其可以**将一个样本映射到一个更高维的空间内**，该核函数是**应用最广**的一个，无论大样本还是小样本都有比较好的性能，而且**其相对于多项式核函数参数要少**，因此大多数情况下在不知道用什么核函数的时候，优先使用高斯核函数



**④sigmoid核函数**
$$
\kappa\left(x, x_{i}\right)=\tanh \left(\eta<x, x_{i}>+\theta\right)
$$


采用sigmoid核函数，支持向量机实现的就是一种多层神经网络



- 如果特征的数量大到和样本数量差不多，则选用LR或者线性核的SVM；
- 如果特征的数量小，样本的数量正常，则选用SVM+高斯核函数；
- 如果特征的数量小，而样本的数量很大，则需要手工添加一些特征从而变成第一种情况；












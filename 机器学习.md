# 机器学习



https://www.bilibili.com/video/BV1dJ411B7gh?p=4&spm_id_from=pageDriver



监督学习：SVM、神经网络

无监督学习：EM、clustering、PCA

半监督学习

强化学习：自动驾驶





## SVM—支持向量机



支持向量机是一种**二分类模型**，它的基本模型是**定义在特征空间上的间隔最大的线性分类器**，**间隔最大使它有别于感知机**；SVM还包括**核技巧**，这使它成为**实质上的非线性分类器**，SVM的**学习策略就是间隔最大化**，可形式化为一个求解凸二次规划的问题，也**等价于正则化的合页损失函数的最小化问题**，**SVM的的学习算法就是求解凸二次规划的最优化算法**；



**1.SVM的原理**

SVM学习的基本想法是求解**能够正确划分训练数据集并且几何间隔最大的分离超平面**
$$
\boldsymbol{w} \cdot x+b=0
$$
即为分离超平面，对于线性可分的数据集来说，这样的超平面有无穷多个（即感知机），但是几何间隔最大的分离超平面却是唯一的



**2. SVM的核函数了解哪些  为什么要用核函数**

当样本在原始空间线性不可分时，可将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分：



**①线性核函数**
$$
\kappa\left(x, x_{i}\right)=x \cdot x_{i}
$$
线性核，主要用于线性可分的情况，我们可以看到特征空间到输入空间的维度是一样的，其参数少速度快，对于线性可分数据，其分类效果很理想



**②多项式核函数**
$$
\kappa\left(x, x_{i}\right)=\left(\left(x \cdot x_{i}\right)+1\right)^{d}
$$